<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-08-27T16:53:13+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ajith Raghavan</title><subtitle>Ajith Raghavan&apos;s personal Tech blog sharing insights and tutorials about Technology, Programming, AI, Machine Learning</subtitle><author><name>Ajith Raghavan</name></author><entry><title type="html">ğŸï¸ CNN Basics</title><link href="http://localhost:4000/blog/cnn-intro-copy/" rel="alternate" type="text/html" title="ğŸï¸ CNN Basics" /><published>2025-08-26T00:00:00+05:30</published><updated>2025-08-26T00:00:00+05:30</updated><id>http://localhost:4000/blog/cnn-intro%20copy</id><content type="html" xml:base="http://localhost:4000/blog/cnn-intro-copy/"><![CDATA[<h2 id="-convnet">â¿» ConvNet</h2>

<p>â˜ï¸- This should be best(available) Emoji ğŸ˜‰ - <a href="https://ajithraghavan.github.io/blog/emoji-generator/">Emoji Generator</a></p>

<p>Convolution Neural Network (CNN or ConvNet) is a type of Neural Network, which is good at processing image</p>

<p>We do Convolution(Cross Correlation), by following BUT much larger and bigger</p>

<p>Yes, now also, still competitive to ViT(Vision Transformer)</p>

<p>With ConvNet we can do,</p>

<h3 id="image-classification">Image Classification</h3>

<p>Where we classify image, like what contains in an image</p>

<p>Some Models are:</p>

<ol>
  <li>AlexNet</li>
  <li>VGGNet(16, 19)</li>
  <li>Inception(Very different approach)</li>
  <li>ResNet(Responsible for Residual Connection which is used in Transformers too!)</li>
</ol>

<h3 id="object-detection">Object Detection</h3>

<p>Detect and draw Bounding Box around the objects in the image like Car, Pedastrian</p>

<p>Some Models are:</p>

<ol>
  <li>R-CNN</li>
  <li>YOLO
    <ul>
      <li>YOLO is such an amazing Paper covers cool topics like:
        <ol>
          <li>Intersection Over Union(IoU)</li>
          <li>Non-Max Suppression</li>
          <li>Anchor Boxes</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

<h3 id="image-segmentation">Image Segmentation</h3>

<p>Where we paint the color around possible Objects in an image</p>

<p>Some Models are:</p>

<ol>
  <li>FCN</li>
  <li>Uâ€‘Net ğŸ˜</li>
</ol>

<p>And much more CNN Models</p>

<p>Let us discuss more in another Post!</p>

<h3 id="what-deep-convnet-learns">What Deep ConvNet Learns?</h3>

<p>The crucial question CNN have these layers, what these layers learn?</p>

<p>Let us Consider this image and let us consider that this CNN has 4 Layers</p>

<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/image-classification-model-6731d4bb5c389.webp" alt="Image" />
Source : <a href="analyticsvidhya.com">Analytics Vidhya</a></p>

<p>It might Learn the Features like,</p>

<p>First Layer :  â€œStraight Lineâ€, â€œCross Linesâ€, etc</p>

<p>Second Layer : â€œCurvesâ€, â€œ Common Patternâ€, etc</p>

<p>Third Layer : â€œCat Noseâ€, â€œDog Earsâ€ etc</p>

<p>Fourth Layer : â€œCat Faceâ€, â€œDog Faceâ€ etc</p>

<blockquote>
  <p>Earlier Layers learns small patters like Lines, Shapes and</p>
</blockquote>

<blockquote>
  <p>Deep Layers will Learn Complex Features like Nose, Ears, even Face etc</p>
</blockquote>

<p>Thanks for reading</p>]]></content><author><name>Ajith Raghavan</name></author><category term="ğŸ§‘â€ğŸ’» ML" /><category term="Neural Network" /><category term="CNN" /><summary type="html"><![CDATA[CNN Basics]]></summary></entry><entry><title type="html">Neural Style Transfer Basics</title><link href="http://localhost:4000/blog/nst-intro/" rel="alternate" type="text/html" title="Neural Style Transfer Basics" /><published>2025-08-26T00:00:00+05:30</published><updated>2025-08-26T00:00:00+05:30</updated><id>http://localhost:4000/blog/nst-intro</id><content type="html" xml:base="http://localhost:4000/blog/nst-intro/"><![CDATA[<h2 id="neural-style-transfernst">Neural Style Transfer(NST)</h2>

<p>It is a technique to apply the â€œfilterâ€ technically â€œStyleâ€ to your â€œoriginalâ€ technically â€œContentâ€ image, it would come under an umbrella of GenAI(not that much)</p>

<p>Goal of NST is to preserve the Content of the Content Image and also to apply the Style of the Style Reference Image!</p>

<p>To understand NST better we need to understand what is CNN and what is learns?</p>

<p><a href="https://ajithraghavan.github.io/blog/cnn-intro/">Please learn here</a></p>

<h2 id="ï¸-back-to-nst">â†ªï¸ Back to NST!</h2>

<p>What each Layers in ConvNet is the main anchor we come back to NST for understanding!</p>

<p>In NST like Typical Neural Network, we wonâ€™t let learn the Parameters of the Neural Network by using Loss Function, but we will compute loss between Content, Style and Generated Image</p>

<p>ğŸ˜ Cool right?</p>

<h3 id="generating-procedure">Generating Procedure</h3>
<p>To generate and image with Content Image in Style of Style Image we need to have Cost Function to tell us each like,</p>

<p>How much different is Generated Image from Content Image?</p>

<p>How much different is Generated Image from Style Image?</p>

<h5 id="content-cost-function-">Content Cost Function :</h5>
<p>How different the Generated Image is from Content Image</p>
<div align="center">
    $$J_{\text{content}}(C, G) = \frac{1}{2} \sum_{i,j} \left(F_{ij}^G - F_{ij}^C\right)^2$$
</div>

<h5 id="style-loss-for-a-single-layer-">Style Loss for a Single Layer :</h5>
<p>We say â€œStyleâ€ as a Correlation between Activations across channels</p>
<div align="center">
    $$J_{style} = \frac{1}{4N_l^2M_l^2} \sum_{i,j} \left(G_{ij}^G - G_{ij}^S\right)^2$$
</div>
<p>Correlation tells you which of the â€œHigh Level Textureâ€ components tends to occur or not occur together in part of the image</p>

<p>So, Degree of Correlation gives us one way of measuring this</p>

<p>Across Channels we will find Correlation like if the image has Specific Texture how much degree Another Texture exists</p>

<p>We can assume ,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. Specific Texture as "Vertical Lines", "Cross Lines", etc

2. Another Texture as "Cross Lines", etc
</code></pre></div></div>

<p>Correlated : Means whenever the part of the image has Specific Texture, that part of the image will probably have Another Texture</p>

<p>Uncorrelated : Means whenever the part of the image has Specific Texture, probably wonâ€™t have Another Texture</p>

<p>For that we need Gram Matrix to do that!</p>
<h5 id="gram-matrix--">Gram Matrix  :</h5>

<div align="center">
    $$G_{ij}^l = \sum_{k} F_{ik}^l F_{jk}^l$$
</div>

<h5 id="total-loss-">Total Loss :</h5>
<p>Now we Compute the Total Loss and Optimize the Generated Image and get our desired Style Image</p>

<div align="center">
    $$J_{\text{total}}(C, S, G) = \alpha J_{\text{content}}(C, G) + \beta J_{\text{style}}(S, G)$$
</div>

<blockquote>
  <p>We get, Generated Image in the Content of Content Image and Style of Style Image</p>
</blockquote>

<p>Thanks for reading</p>]]></content><author><name>Ajith Raghavan</name></author><category term="ğŸ§‘â€ğŸ’» ML" /><category term="Neural Network" /><category term="CNN" /><summary type="html"><![CDATA[NST Basics]]></summary></entry><entry><title type="html">Try My ~3.5 Million Parameters Model Instead for âœ¨ğŸ˜‰</title><link href="http://localhost:4000/blog/emoji-generator-copy/" rel="alternate" type="text/html" title="Try My ~3.5 Million Parameters Model Instead for âœ¨ğŸ˜‰" /><published>2025-08-24T00:00:00+05:30</published><updated>2025-08-24T00:00:00+05:30</updated><id>http://localhost:4000/blog/emoji-generator%20copy</id><content type="html" xml:base="http://localhost:4000/blog/emoji-generator-copy/"><![CDATA[<h2 id="intro">ğŸ˜Š Introduction</h2>

<p>I thought to Build a Machine Learning Model to generate Emojis for My Writing content</p>

<p>Like when typing some sentences, I think I need relevant Emojis in the sentences, as it will give more expressiveness, right</p>

<p>And also because currently I am searching in Web(using some website like Emoji Finder etc., it is based on keywords only) to pick Emojis</p>

<p>So I decided to Develop a <strong>LSTM Model</strong> to automatically generate Emoji for My Sentences</p>

<h2 id="demo">ğŸ¥ First Demo</h2>
<p><img src="/assets/images/2025-08-24-emoji-generator/output.gif" alt="Demo Video" /></p>

<h2 id="-explanation">ğŸ§‘â€ğŸ« Explanation</h2>

<p>When the user types the paragraph, for each paragraph the Model predicts the approximate Emoji</p>

<p>For example, if you have 5 sentences in a paragraph, the Model will generate 5 Emojis</p>

<h2 id="technical-details">âš™ï¸ Technical Details</h2>

<p>I currently have totally 20 Emojis â¤, ğŸ˜, ğŸ˜‚, ğŸ’•, ğŸ”¥, ğŸ˜Š, ğŸ˜, âœ¨, ğŸ’™, ğŸ˜˜, ğŸ“·, ğŸ‡ºğŸ‡¸, â˜€, ğŸ’œ, ğŸ˜‰, ğŸ’¯, ğŸ˜, ğŸ„, ğŸ“¸, ğŸ˜œ</p>

<p>And used Dataset from <a href="https://huggingface.co/datasets/cardiffnlp/tweet_eval">Hugging Face</a> and used Google Colab for Training</p>

<h3 id="model-selection">ğŸ¯ Model Selection</h3>

<p>I have decided to use BiLSTM(Bidirectional LSTM(Long Short-Term Memory))</p>

<p>We could have just used <strong>LSTM</strong> rather then <strong>BiLSTM</strong> as we are not doing Seq2Seq Task, like we are not translating English to Emojis</p>

<p>But, here <strong>BiLSTM</strong> improves the performance by at least 10%</p>

<p>So, decided to use <strong>BiLSTM</strong></p>

<blockquote>
  <p>Note :</p>
</blockquote>

<blockquote>
  <p>Here we could have used BiLSTM with Attention Mechanism or even  Fine-Tuned Pre Trained Model like BERT</p>
</blockquote>

<blockquote>
  <p>But decided to use BiLSTM</p>
</blockquote>

<h3 id="architecture">ğŸ—ï¸ Architecture</h3>

<ol>
  <li>First have used Embedding Layer</li>
  <li>Then, BiLSTM with 2 Layers</li>
  <li>Dropout for Regularization</li>
  <li>Then Linear Layer with 20 output units for each Emojis
    <ul>
      <li>Note :</li>
      <li>We are using BiLSTM, so it will hidden states from both the directions</li>
      <li>So, before passing to Linear Layer we must concatenate both the hidden states</li>
    </ul>
  </li>
</ol>

<h3 id="hyperparameters">ğŸ² Hyperparameters</h3>

<ol>
  <li>I have used the Maximum length of the Sequence to be <code class="language-plaintext highlighter-rouge">50</code></li>
  <li>Embedding Dimension as <code class="language-plaintext highlighter-rouge">128</code></li>
  <li>Hidden Dimension for LSTM States to be <code class="language-plaintext highlighter-rouge">128</code></li>
  <li>As stated before, we have chosen Number of Layers to be 2</li>
  <li>Learning Rate Î± : 0.0005</li>
</ol>

<h3 id="accuracy-and-important-study">ğŸš¨Â Accuracy and Important Study</h3>

<p>Regarding Accuracy, it is relatively low although with <strong>BiLSTM</strong> and even low with <strong>Unidirectional LSTM</strong></p>

<p>Was tweaking and trying to improve the performance then LATER ONLY realized that data has Class Imbalance Problem</p>

<p>Where ~21% of the Data has â€œâ¤â€ which dominates most and followed by ~10% of Data has â€œğŸ˜â€ and so onâ€¦ then â€œğŸ˜œâ€ was barely minimum</p>

<h4 id="ï¸-important-action">âš ï¸ Important action</h4>

<p>ğŸ¥‡ First Rule : Data in Training Set, Development Set and Test Set should follow the same Distribution</p>

<p>Followed by, may be here, we can Augmented Data Synthetically, or may be with some other Architecture so on</p>

<p>Yes, we can also increase Accuracy with the same Data but as of now saved that for later</p>

<h3 id="little-history">ğŸ“œ Little History</h3>

<p>I have used Regular LSTM and saw the Model was Overfitting</p>

<p>So, of various Hyperparameters(still overfitting) after few tweaking various Hyperparameters along with  BiLSTM showed little improvement and continued and seems to work fine</p>

<p>Thanks for reading</p>]]></content><author><name>Ajith Raghavan</name></author><category term="ğŸ§‘â€ğŸ’» ML" /><category term="Neural Network" /><category term="RNN" /><category term="LSTM" /><summary type="html"><![CDATA[Try My ~3.5 Million Parameters Model Instead for âœ¨ğŸ˜‰ for Emoji Generation]]></summary></entry><entry><title type="html">First Post</title><link href="http://localhost:4000/blog/first-post/" rel="alternate" type="text/html" title="First Post" /><published>2025-08-24T00:00:00+05:30</published><updated>2025-08-24T00:00:00+05:30</updated><id>http://localhost:4000/blog/first-post</id><content type="html" xml:base="http://localhost:4000/blog/first-post/"><![CDATA[<h2 id="intro">About Me</h2>

<p>ğŸ‘‹ Hi, I am Ajith Raghavan Welcome to my tech blog where I share insights and tutorials on technology, programming, AI, and machine learning.</p>

<p>Let us explore ğŸš€</p>

<h2 id="contact">About This Blog</h2>

<p>This blog was created in 2025 as a platform to share knowledge, insights, and tutorials about technologies I work with and find interesting.</p>

<p>Here youâ€™ll find articles about:</p>

<ul>
  <li>Programming languages and frameworks</li>
  <li>AI and Machine Learning concepts</li>
  <li>Technical tutorials and guides</li>
  <li>Thoughts on emerging Technologies</li>
</ul>]]></content><author><name>Ajith Raghavan</name></author><category term="ğŸ§‘â€ğŸ’» Tech" /><category term="ğŸ™‹ Intro" /><summary type="html"><![CDATA[Welcome to my tech blog where I share insights and tutorials on technology, programming, AI, and machine learning.]]></summary></entry></feed>