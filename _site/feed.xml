<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-08-25T00:54:11+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ajith Raghavan</title><subtitle>Ajith Raghavan&apos;s personal Tech blog sharing insights and tutorials about Technology, Programming, AI, Machine Learning</subtitle><author><name>Ajith Raghavan</name></author><entry><title type="html">Try My ~3.5 Million Model Instead for âœ¨ğŸ˜‰</title><link href="http://localhost:4000/blog/emoji-generator/" rel="alternate" type="text/html" title="Try My ~3.5 Million Model Instead for âœ¨ğŸ˜‰" /><published>2025-08-24T00:00:00+05:30</published><updated>2025-08-24T00:00:00+05:30</updated><id>http://localhost:4000/blog/emoji-generator</id><content type="html" xml:base="http://localhost:4000/blog/emoji-generator/"><![CDATA[<h2 id="intro">ğŸ˜Š Introduction</h2>

<p>I thought to Build a Machine Learning Model to generate Emojis for My Writing content</p>

<p>Like when typing some sentences, I think I need relevant Emojis in the sentences, as it will give more expressiveness, right</p>

<p>And also because currently I am searching in Web(using some website like Emoji Finder etc., it is based on keywords only) to pick Emojis</p>

<p>So I decided to Develop a <strong>LSTM Model</strong> to automatically generate Emoji for My Sentences</p>

<h2 id="demo">ğŸ¥ First Demo</h2>
<p><img src="/assets/images/2025-08-24-emoji-generator/output.gif" alt="Demo Video" /></p>

<h2 id="-explanation">ğŸ§‘â€ğŸ« Explanation</h2>

<p>When the user types the paragraph, for each paragraph the Model predicts the approximate Emoji</p>

<p>For example, if you have 5 sentences in a paragraph, the Model will generate 5 Emojis</p>

<h2 id="technical-details">âš™ï¸ Technical Details</h2>

<p>I currently have totally 20 Emojis â¤, ğŸ˜, ğŸ˜‚, ğŸ’•, ğŸ”¥, ğŸ˜Š, ğŸ˜, âœ¨, ğŸ’™, ğŸ˜˜, ğŸ“·, ğŸ‡ºğŸ‡¸, â˜€, ğŸ’œ, ğŸ˜‰, ğŸ’¯, ğŸ˜, ğŸ„, ğŸ“¸, ğŸ˜œ</p>

<p>And used Dataset from <a href="https://huggingface.co/datasets/cardiffnlp/tweet_eval">Hugging Face</a> and used Google Colab for Training</p>

<h3 id="model-selection">ğŸ¯ Model Selection</h3>

<p>I have decided to use BiLSTM(Bidirectional LSTM(Long Short-Term Memory))</p>

<p>We could have just used <strong>LSTM</strong> rather then <strong>BiLSTM</strong> as we are not doing Seq2Seq Task, like we are not translating English to Emojis</p>

<p>But, here <strong>BiLSTM</strong> improves the performance by at least 10%</p>

<p>So, decided to use <strong>BiLSTM</strong></p>

<blockquote>
  <p>Note :</p>
</blockquote>

<blockquote>
  <p>Here we could have used BiLSTM with Attention Mechanism or even  Fine-Tuned Pre Trained Model like BERT</p>
</blockquote>

<blockquote>
  <p>But decided to use BiLSTM</p>
</blockquote>

<h3 id="architecture">ğŸ—ï¸ Architecture</h3>

<ol>
  <li>First have used Embedding Layer</li>
  <li>Then, BiLSTM with 2 Layers</li>
  <li>Dropout for Regularization</li>
  <li>Then Linear Layer with 20 output units for each Emojis
    <ul>
      <li>Note :</li>
      <li>We are using BiLSTM, so it will hidden states from both the directions</li>
      <li>So, before passing to Linear Layer we must concatenate both the hidden states</li>
    </ul>
  </li>
</ol>

<h3 id="hyperparameters">ğŸ² Hyperparameters</h3>

<ol>
  <li>I have used the Maximum length of the Sequence to be <code class="language-plaintext highlighter-rouge">50</code></li>
  <li>Embedding Dimension as <code class="language-plaintext highlighter-rouge">128</code></li>
  <li>Hidden Dimension for LSTM States to be <code class="language-plaintext highlighter-rouge">128</code></li>
  <li>As stated before, we have chosen Number of Layers to be 2</li>
  <li>Learning Rate Î± : 0.0005</li>
</ol>

<h3 id="accuracy-and-important-study">ğŸš¨Â Accuracy and Important Study</h3>

<p>Regarding Accuracy, it is relatively low although with <strong>BiLSTM</strong> and even low with <strong>Unidirectional LSTM</strong></p>

<p>Was tweaking and trying to improve the performance then LATER ONLY realized that data has Class Imbalance Problem</p>

<p>Where ~21% of the Data has â€œâ¤â€ which dominates most and followed by ~10% of Data has â€œğŸ˜â€ and so onâ€¦ then â€œğŸ˜œâ€ was barely minimum</p>

<h4 id="ï¸-important-action">âš ï¸ Important action</h4>

<p>ğŸ¥‡ First Rule : Data in Training Set, Development Set and Test Set should follow the same Distribution</p>

<p>Followed by, may be here, we can Augmented Data Synthetically, or may be with some other Architecture so on</p>

<p>Yes, we can also increase Accuracy with the same Data but as of now saved that for later</p>

<h3 id="little-history">ğŸ“œ Little History</h3>

<p>I have used Regular LSTM and saw the Model was Overfitting</p>

<p>So, of various Hyperparameters(still overfitting) after few tweaking various Hyperparameters along with  BiLSTM showed little improvement and continued and seems to work fine</p>

<p>Thanks for reading</p>]]></content><author><name>Ajith Raghavan</name></author><category term="ğŸ§‘â€ğŸ’» ML" /><category term="Neural Network" /><category term="RNN" /><category term="LSTM" /><summary type="html"><![CDATA[Try My ~3.5 Million Model Instead for âœ¨ğŸ˜‰ for Emoji Generation]]></summary></entry><entry><title type="html">First Post</title><link href="http://localhost:4000/blog/first-post/" rel="alternate" type="text/html" title="First Post" /><published>2025-08-24T00:00:00+05:30</published><updated>2025-08-24T00:00:00+05:30</updated><id>http://localhost:4000/blog/first-post</id><content type="html" xml:base="http://localhost:4000/blog/first-post/"><![CDATA[<h2 id="intro">About Me</h2>

<p>ğŸ‘‹ Hi, I am Ajith Raghavan Welcome to my tech blog where I share insights and tutorials on technology, programming, AI, and machine learning.</p>

<p>Let us explore ğŸš€</p>

<h2 id="contact">About This Blog</h2>

<p>This blog was created in 2025 as a platform to share knowledge, insights, and tutorials about technologies I work with and find interesting.</p>

<p>Here youâ€™ll find articles about:</p>

<ul>
  <li>Programming languages and frameworks</li>
  <li>AI and Machine Learning concepts</li>
  <li>Technical tutorials and guides</li>
  <li>Thoughts on emerging Technologies</li>
</ul>]]></content><author><name>Ajith Raghavan</name></author><category term="ğŸ§‘â€ğŸ’» Tech" /><category term="ğŸ™‹ Intro" /><summary type="html"><![CDATA[Welcome to my tech blog where I share insights and tutorials on technology, programming, AI, and machine learning.]]></summary></entry></feed>